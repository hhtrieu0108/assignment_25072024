{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scala Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://Laptop:4040\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1722326488412)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.SparkConf\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "import org.apache.spark.rdd.RDD\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.rdd.RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@3b6b0448\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder()\n",
    "                        .appName(\"Assignment 25072024\")\n",
    "                        .master(\"local[*]\")\n",
    "                        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@16f23455\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.math.sqrt\r\n",
       "import scala.math.ceil\r\n",
       "isPrime: (n: Int)Boolean\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.math.sqrt\n",
    "import scala.math.ceil\n",
    "\n",
    "def isPrime(n: Int): Boolean = {\n",
    "    if (n <= 1) {\n",
    "        false\n",
    "    } else {\n",
    "        val upperBound = ceil(sqrt(n)).toInt\n",
    "        !(2 to upperBound).exists(i => n % i == 0)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numbers_file: String = input_data/numbers.txt\r\n",
       "prime_numbers_rdd_output_path: String = output_data/prime_numbers_rdd.txt\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numbers_file = \"input_data/numbers.txt\"\n",
    "val prime_numbers_rdd_output_path = \"output_data/prime_numbers_rdd.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numbers_rdd: org.apache.spark.rdd.RDD[String] = input_data/numbers.txt MapPartitionsRDD[1] at textFile at <console>:33\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numbers_rdd: RDD[String] = sc.textFile(numbers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numbers_rdd_int: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[2] at map at <console>:32\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numbers_rdd_int: RDD[Int] = numbers_rdd.map(x => x.toInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primeNumbersRDD: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[3] at filter at <console>:33\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val primeNumbersRDD: RDD[Int] = numbers_rdd_int.filter(isPrime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textFile_path: String = input_data/textLine.txt\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val textFile_path = \"input_data/textLine.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd: org.apache.spark.rdd.RDD[String] = input_data/textLine.txt MapPartitionsRDD[5] at textFile at <console>:33\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = sc.textFile(textFile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convertToKeyValue: (value: String)(Char, String)\r\n",
       "convertToKeyLenValue: (value: String)(Int, Int)\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convertToKeyValue(value: String): (Char, String) = {\n",
    "    val parts = value.split(',').map(_.trim)\n",
    "    val key = parts(0).head\n",
    "    val valuePart = parts(1)\n",
    "    (key, valuePart)\n",
    "}\n",
    "\n",
    "\n",
    "def convertToKeyLenValue(value: String): (Int, Int) = {\n",
    "    val parts = value.split(',').map(_.trim)\n",
    "    val key = parts(0).toInt\n",
    "    val length = parts(1).length\n",
    "    (key, length)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key_lenValue_rdd: org.apache.spark.rdd.RDD[(Int, Int)] = MapPartitionsRDD[7] at map at <console>:33\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val key_lenValue_rdd = rdd.map(convertToKeyLenValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Array[(Int, Int)] = Array((49,21), (10,21), (39,21), (86,21), (69,21))\r\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_lenValue_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sumCount: (value: Iterable[Int])(Int, Int)\r\n",
       "avgCalGroupByKey: (value: (Int, Int))Double\r\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sumCount(value: Iterable[Int]): (Int, Int) = {\n",
    "    val totalSum = value.sum\n",
    "    val count = value.size\n",
    "    (totalSum, count)\n",
    "}\n",
    "\n",
    "def avgCalGroupByKey(value: (Int, Int)): Double = {\n",
    "    val (sum, count) = value\n",
    "    sum.toDouble / count\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grouped_rdd: org.apache.spark.rdd.RDD[(Int, Iterable[Int])] = ShuffledRDD[11] at groupByKey at <console>:36\r\n",
       "sum_count_rdd: org.apache.spark.rdd.RDD[(Int, (Int, Int))] = MapPartitionsRDD[12] at mapValues at <console>:38\r\n",
       "avg_rdd_groupByKey: org.apache.spark.rdd.RDD[(Int, Double)] = MapPartitionsRDD[13] at mapValues at <console>:40\r\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val grouped_rdd = key_lenValue_rdd.groupByKey()\n",
    "\n",
    "val sum_count_rdd = grouped_rdd.mapValues(sumCount)\n",
    "\n",
    "val avg_rdd_groupByKey = sum_count_rdd.mapValues(avgCalGroupByKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Array[(Int, Double)] = Array((96,23.92222222222222), (34,23.956989247311828), (52,23.89516129032258), (4,23.893617021276597), (16,23.892857142857142), (82,23.852631578947367), (66,23.916666666666668), (80,23.846153846153847), (54,23.9375), (28,23.894736842105264), (98,23.882978723404257), (30,23.90625), (50,23.855555555555554), (14,23.870967741935484), (92,23.840425531914892), (24,23.94736842105263), (64,23.921348314606742), (36,23.887755102040817), (74,23.877777777777776), (90,23.858585858585858), (72,23.858823529411765), (70,23.905982905982906), (18,23.8018018018018), (12,23.91919191919192), (38,23.876543209876544), (20,23.918181818181818), (78,23.945652173913043), (10,23.86868686868687), (94,23.914893617021278), (100,23.87719298245614), (84,23.875), (56,23.86021505376344), (76,...\r\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rdd_groupByKey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valueAndCount: (value: Int)(Int, Int)\r\n",
       "sumLenValue: (value1: (Int, Int), value2: (Int, Int))(Int, Int)\r\n",
       "avgCalReduceByKey: (value: (Int, Int))Double\r\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def valueAndCount(value: Int): (Int, Int) = {\n",
    "    (value, 1)\n",
    "}\n",
    "\n",
    "def sumLenValue(value1: (Int, Int), value2: (Int, Int)): (Int, Int) = {\n",
    "    (value1._1 + value2._1, value1._2 + value2._2)\n",
    "}\n",
    "\n",
    "def avgCalReduceByKey(value: (Int, Int)): Double = {\n",
    "    value._1.toDouble / value._2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum_count_rdd: org.apache.spark.rdd.RDD[(Int, (Int, Int))] = ShuffledRDD[15] at reduceByKey at <console>:37\r\n",
       "avg_rdd_reduceByKey: org.apache.spark.rdd.RDD[(Int, Double)] = MapPartitionsRDD[16] at mapValues at <console>:39\r\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sum_count_rdd = key_lenValue_rdd.mapValues(valueAndCount)\n",
    "                                .reduceByKey(sumLenValue)\n",
    "\n",
    "val avg_rdd_reduceByKey = sum_count_rdd.mapValues(avgCalReduceByKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res7: Array[(Int, Double)] = Array((34,23.956989247311828), (52,23.89516129032258), (96,23.92222222222222), (4,23.893617021276597), (16,23.892857142857142), (82,23.852631578947367), (66,23.916666666666668), (28,23.894736842105264), (54,23.9375), (80,23.846153846153847), (98,23.882978723404257), (30,23.90625), (14,23.870967741935484), (50,23.855555555555554), (36,23.887755102040817), (24,23.94736842105263), (64,23.921348314606742), (92,23.840425531914892), (74,23.877777777777776), (90,23.858585858585858), (72,23.858823529411765), (70,23.905982905982906), (18,23.8018018018018), (12,23.91919191919192), (38,23.876543209876544), (20,23.918181818181818), (78,23.945652173913043), (10,23.86868686868687), (94,23.914893617021278), (84,23.875), (100,23.87719298245614), (56,23.86021505376344), (76,...\r\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rdd_reduceByKey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
